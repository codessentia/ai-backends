{
  "providers": {
    "openai": {
      "enabled": true,
      "models": [
        { "name": "gpt-4o-mini", "capabilities": ["summarize", "keywords", "sentiment", "vision"], "notes": "OpenAI multimodal small model with vision support." },
        { "name": "gpt-4.1-nano", "capabilities": ["summarize", "keywords", "sentiment"], "notes": "OpenAI lightweight model for fast, low-cost text tasks." },
        { "name": "gpt-5-nano", "capabilities": ["summarize", "keywords", "sentiment", "askText"], "notes": "OpenAI next-gen nano model with Q&A capabilities." }
      ]
    },
    "ollama": {
      "enabled": true,
      "models": [
        { "name": "llama3.2:latest", "capabilities": ["summarize", "keywords", "sentiment"], "notes": "Meta Llama 3.2 general-purpose model." },
        { "name": "qwen2.5-coder:latest", "capabilities": ["summarize", "keywords"], "notes": "Qwen 2.5 coder-optimized variant for code tasks." },
        { "name": "gemma2:2b", "capabilities": ["summarize", "keywords", "sentiment", "emailReply"], "notes": "Gemma 2 small variant for lightweight tasks." },
        { "name": "gemma3:4b", "capabilities": ["summarize", "keywords", "sentiment", "emailReply", "askText"], "notes": "Gemma 3 small variant for lightweight tasks with Q&A support." },
        { "name": "qwen2.5:0.5b", "capabilities": ["summarize", "keywords", "sentiment"], "notes": "Qwen 2.5 0.5B parameter model for ultra-light workloads." },
        { "name": "qwen2.5:1.5b", "capabilities": ["summarize", "keywords", "sentiment"], "notes": "Qwen 2.5 1.5B parameter model; balanced speed/quality." },
        { "name": "qwen2.5:3b", "capabilities": ["summarize", "keywords", "sentiment"], "notes": "Qwen 2.5 3B parameter model for stronger quality." },
        { "name": "qwen2.5:7b", "capabilities": ["summarize", "keywords", "sentiment"], "notes": "Qwen 2.5 7B parameter model for higher quality." },
        { "name": "phi3:3.8b", "capabilities": ["summarize", "keywords", "sentiment"], "notes": "Phi-3 mini variant (3.8B) for small, efficient tasks." },
        { "name": "phi3:14b", "capabilities": ["summarize", "keywords", "sentiment"], "notes": "Phi-3 medium variant (14B) for improved reasoning." },
        { "name": "llama3.2:1b", "capabilities": ["summarize", "keywords", "sentiment"], "notes": "Llama 3.2 1B tiny variant for edge/light usage." },
        { "name": "llama3.2:3b", "capabilities": ["summarize", "keywords", "sentiment"], "notes": "Llama 3.2 3B small variant." },
        { "name": "smollm2:135m", "capabilities": ["summarize", "keywords", "sentiment"], "notes": "SmolLM2 135M ultra-compact model." },
        { "name": "smollm2:360m", "capabilities": ["summarize", "keywords", "sentiment"], "notes": "SmolLM2 360M compact model." },
        { "name": "smollm2:1.7b", "capabilities": ["summarize", "keywords", "sentiment"], "notes": "SmolLM2 1.7B larger small model." },
        { "name": "nemotron-mini:4b", "capabilities": ["summarize", "keywords", "sentiment"], "notes": "NVIDIA Nemotron-mini 4B general-purpose model." }
      ]
    },
    "openrouter": {
      "enabled": true,
      "models": [
        { "name": "anthropic/claude-3.5-sonnet", "capabilities": ["summarize", "keywords", "sentiment"], "notes": "Claude 3.5 Sonnet via OpenRouter; strong reasoning." },
        { "name": "openai/gpt-4o-mini", "capabilities": ["summarize", "keywords", "sentiment"], "notes": "OpenRouter proxy to GPT-4o mini." },
        { "name": "google/gemini-2.0-flash-lite-001", "capabilities": ["summarize", "keywords", "sentiment", "askText"], "notes": "Google Gemini 2.0 Flash Lite via OpenRouter with Q&A capabilities." },
        { "name": "google/gemini-2.5-flash-lite", "capabilities": ["summarize", "keywords", "sentiment", "askText"], "notes": "Google Gemini 2.5 Flash Lite via OpenRouter with 1M token context window for large document Q&A." }
      ]
    },
    "anthropic": {
      "enabled": true,
      "models": [
        { "name": "claude-3-haiku-20240307", "capabilities": ["summarize", "keywords", "sentiment", "askText"], "notes": "Anthropic Claude 3 Haiku; fast and cost-effective with Q&A support." }
      ]
    }
  }
}


